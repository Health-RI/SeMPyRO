{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef630c0-1c7b-4aea-b674-0772d5085aec",
   "metadata": {},
   "source": [
    "# Preparing and uploading data to Fair Data Point with SeMPyRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922cecf-a9dd-46e6-a219-91e0b7d8371a",
   "metadata": {},
   "source": [
    "In this notebook we will go trough the steps of defining a simple metadata set consisting of a DCAT:Catalog and DCAT:Dataset. We will load some example data and serialize it to a turtle file or push it to a FAIR Data Point (FDP). \n",
    "\n",
    "**Prerequisites:** To execute this notebook in full one needs to have a running FAIR Data Point (FDP) instance with an active write access account.\n",
    "This notebook is written for the reference implementation, FAIR Data Point version 1.16 with default SHACL shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053b016-75be-4515-8916-3cd86e79a3e0",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfd609d-c0b5-4d78-bb72-2174ec31e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from rdflib import URIRef, DCTERMS\n",
    "from pydantic import AnyHttpUrl, Field, field_validator\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "from fairclient.fdpclient import FDPClient\n",
    "\n",
    "from sempyro import LiteralField\n",
    "from sempyro.dcat import DCATCatalog, DCATDataset\n",
    "from sempyro.vcard import VCard\n",
    "from sempyro.foaf import Agent\n",
    "from sempyro.utils.validator_functions import force_literal_field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b484768-a3ec-430f-9195-ab1ccaf774c0",
   "metadata": {},
   "source": [
    "## Defining a Catalog and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f8dfe-10f7-4cc0-9c22-15b850c0b086",
   "metadata": {},
   "source": [
    "The function of SeMPyRO is to define objects according to a specification, such as dcat:Catalog and dcat:Dataset, and validate the metadata agains this specification. The metadata for the datasets we will use for this demo is in `example_data_fdp.csv`. \n",
    "The FDP specification requires that each dataset is a part of a catalog, therefore we need to create a catalog. \n",
    "\n",
    "To see what we need to provide for that we can annotate the model and request the mandatory fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff57267-1900-4b21-a8c5-fd5e16c61342",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_fields = DCATCatalog.annotate_model()\n",
    "print(catalog_fields.mandatory_fields())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8b731-d5b8-43aa-9a93-6c4781f51393",
   "metadata": {},
   "source": [
    "Let's create a minimum catalogue with an example title and description. We also need a URI to use as a graph subject at serialization. Let's use `example.com` domain for now for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6386d80-2162-4d75-8633-38891dbda728",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_subject = URIRef(\"http://example.com/test_catalog_1\")\n",
    "\n",
    "catalog = DCATCatalog(title=[LiteralField(value=\"Test catalog\", language=\"en\")],\n",
    "                      description=[LiteralField(value=\"Catalog for test example datasets\", language=\"en\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321040d-6c3f-4188-9fed-4c0b8c7ea35f",
   "metadata": {},
   "source": [
    "We can check the serialized output of the current Catalog record to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017f793-7b79-4097-b98b-c3fe664f8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_record = catalog.to_graph(catalog_subject)\n",
    "print(catalog_record.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b950ac5d-82fd-48bd-8fa8-68881a8dd75a",
   "metadata": {},
   "source": [
    "Now let's add datasets to the catalog.\n",
    "Data for example datasets will be fetched from `./example_data_fdp.csv` file. Let's look into the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391c276-214d-4c36-bf22-62b136627aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./example_data_fdp.csv\", sep=\";\")\n",
    "print(tabulate(df, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a222b9-b0d3-42b3-a619-78c720025d39",
   "metadata": {},
   "source": [
    "We need to modify some of the text formatting to align it with the standard. Each contact point also needs to be formatted in a VCard (vCard:Kind) object. This is also a model class from SeMPyRO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf6315c-fce0-4f00-b430-586f167eebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"keywords\"] = df[\"keywords\"].apply(lambda x: [y.strip() for y in x.split(\",\")])\n",
    "df[\"theme\"] = df[\"theme\"].apply(lambda x: x.split(\",\"))\n",
    "df[\"id\"] = df[\"id\"].apply(lambda x: [str(x)])\n",
    "df[\"contact_point\"] = df.apply(\n",
    "    lambda x: VCard(hasEmail=x[\"contact_point\"], full_name=[x[\"author_name\"]], hasUID=x[\"author_id\"]), axis=1\n",
    ")\n",
    "datasets = df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466020b5-76d6-4336-9719-fa6075624f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for record in datasets:\n",
    "    dataset = DCATDataset(\n",
    "        title=[LiteralField(value=record[\"name\"])],\n",
    "        description=[LiteralField(value=record[\"description\"])],\n",
    "        identifier=record[\"id\"],\n",
    "        creator=[record[\"author_id\"]],\n",
    "        release_date=record[\"issued\"],\n",
    "        theme=record[\"theme\"],\n",
    "        keyword=[LiteralField(value=x) for x in record[\"keywords\"]],\n",
    "        contact_point=[record[\"contact_point\"]]\n",
    "    )\n",
    "    dataset_subject = URIRef(f\"http://example.com/dataset_{record['id'][0]}\")\n",
    "    dataset_list.append({'subject_uri': dataset_subject, 'dataset': dataset})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e12dad-cc00-4c4b-ab01-74d3a2a2d81c",
   "metadata": {},
   "source": [
    "These DCATDataset objects can be serialized individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8d2fb-0253-489f-b242-42bcb8cb1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_dict in dataset_list:\n",
    "    dataset_graph = dataset_dict['dataset'].to_graph(dataset_dict['subject_uri'])\n",
    "    print(dataset_graph.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3061059-e94b-4421-885b-1c5224f1ba3a",
   "metadata": {},
   "source": [
    "The DCATDatasets can be added to the DCATCatalog to link them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7dbaf-dcce-4473-9ef6-9b6e6599125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_objects = [ds_dict['dataset'] for ds_dict in dataset_list]\n",
    "catalog.dataset = dataset_objects\n",
    "catalog_graph = catalog.to_graph(catalog_subject)\n",
    "print(catalog_graph.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb67fe-3847-43e5-9739-64143b1e83e1",
   "metadata": {},
   "source": [
    "Or the DCATDataset and DCATCatalog can be linked through the subject URIs of the DCATDatasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364dd25-6ccf-4726-b3af-2ef726c99dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_uris = [ds_dict['subject_uri'] for ds_dict in dataset_list]\n",
    "catalog.dataset = dataset_uris\n",
    "catalog_graph = catalog.to_graph(catalog_subject)\n",
    "for ds in dataset_list:\n",
    "    catalog_graph += ds['dataset'].to_graph(ds['subject_uri'])\n",
    "print(catalog_graph.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd462ec6-299c-4e9e-96d4-086200ba9177",
   "metadata": {},
   "source": [
    "This output can also be written to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8bb71-c689-486c-bde3-4e4f0b0432e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_graph.serialize(destination=\"./usage_example.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c9ff3-d3bd-472e-add6-93bc609f5f43",
   "metadata": {},
   "source": [
    "## Push to a FAIR Data Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebd317-5168-484d-8592-e753379250d5",
   "metadata": {},
   "source": [
    "The first step in pushing to a FAIR Data Point, is connecting to a FAIR Data Point. For this you need the URL, a username and a password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294b23b-00b9-41a2-bf83-c6932f9ee9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_base = input(\"Enter base link to FDP: \").rstrip(\"/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f50e3-63c0-460a-aece-64a112c30f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(\"Enter username: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cceb04-1120-432e-81f3-135424c7ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass(prompt=\"Password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a7db8",
   "metadata": {},
   "source": [
    "Now connect to FDP with given username and password:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdpclient = FDPClient(base_url=fdp_base, username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265aa53e-0698-4e06-9788-95f864f7c9da",
   "metadata": {},
   "source": [
    "To align with the FDP standard, some modifications need to be made to the model. One requirement is that an object contains a link pointing to a parent object. In the case of a catalogue it is FDP itself and it should be a property `is_part_of` in the range `DCTERMS.isPartOf`. This property is outside of DCAT-AP specification. \n",
    "\n",
    "There are two ways to add it. The first way is to add it directly to a graph after converting the base FDP link to URIRef:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4861c8a-0c81-470d-a1b7-b65c56c5c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_record.add((catalog_subject, DCTERMS.isPartOf, URIRef(fdp_base)))\n",
    "print(catalog_record.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57120302-f30d-4ab5-9172-385cf66bb7e2",
   "metadata": {},
   "source": [
    "The record above can be published to FDP. The second way is to create a subclass of the DCATCatalog class specifically for FDP. This is the way to go if you want to write reusable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39cbff-73f6-4cf0-bba1-a49066822324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subclass of catalog, and add/override the fields different from standard DCAT-AP\n",
    "class FDPCatalog(DCATCatalog):\n",
    "    publisher: List[Agent] = Field(\n",
    "        description=\"The entity responsible for making the resource available.\",\n",
    "        json_schema_extra={\n",
    "            \"rdf_term\": DCTERMS.publisher, \n",
    "            \"rdf_type\": \"uri\",\n",
    "        }\n",
    "    )\n",
    "    is_part_of: [AnyHttpUrl] = Field(description=\"Link to parent object\", \n",
    "                                     json_schema_extra={\n",
    "                                         \"rdf_term\": DCTERMS.isPartOf, \n",
    "                                         \"rdf_type\": \"uri\"\n",
    "                                     })\n",
    "    has_version: LiteralField = Field(\n",
    "        description=\"This resource has a more specific, versioned resource\",\n",
    "        json_schema_extra={\n",
    "            \"rdf_term\": DCTERMS.hasVersion,\n",
    "            \"rdf_type\": \"rdfs_literal\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    @field_validator(\"has_version\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def convert_to_literal(cls, value: Union[str, LiteralField]) -> List[LiteralField]:\n",
    "        return force_literal_field(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252b4f01-b4d8-4830-a2d9-ccc2a85d9be6",
   "metadata": {},
   "source": [
    "In `DCATCatalog` `publisher` field is inherited from DCATResource, is optional and takes either AnyHttpUrl or Agent:\n",
    "```\n",
    "publisher: List[Union[AnyHttpUrl, Agent]] = Field(\n",
    "        default=None,\n",
    "        description=\"The entity responsible for making the resource available.\",\n",
    "        rdf_term=DCTERMS.publisher,\n",
    "        rdf_type=\"uri\"\n",
    "    )\n",
    "```\n",
    "\n",
    "‚ùóNote, that a particular configuration concerning mandatory fields and field types may be defined differently in Shape Constraint Language (SHACL) forms for an FDP instance. In this case you may need to change the example code accordingly to prevent validation errors on uploading data. To review your instance's SHACL forms, go to `<your FDP host>/schemas` and select the resource type of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39504874",
   "metadata": {},
   "source": [
    "So far the catalogue record was compliant with DCAT-AP notation. However, the default FDP shapes require us to add a `publisher` in the form of an `foaf:Agent`. We also add the previously mentioned `is_part_of` field. The `has_version` field must be a single Literal with the default shapes, instead of an IRI list as DCAT-AP specifies as allowed input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbc5a5",
   "metadata": {},
   "source": [
    "Now that we have a valid FDP catalog class, we can fill it with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp_catalog = FDPCatalog(\n",
    "    title=[LiteralField(value=\"Hogwarts research catalog\", language=\"en\")],\n",
    "    description=[LiteralField(value=\"Catalog for Hogwarts students research projects\", language=\"en\")],\n",
    "    publisher=[\n",
    "        Agent(\n",
    "            name=[\"Hogwarts school of Witchcraft and Wizardry\"],\n",
    "            identifier=\"https://harrypotter.fandom.com/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\",\n",
    "        )\n",
    "    ],\n",
    "    is_part_of=[fdp_base],\n",
    "    has_version=\"1.0\",\n",
    ")\n",
    "\n",
    "fdp_catalog_record = fdp_catalog.to_graph(catalog_subject)\n",
    "print(fdp_catalog_record.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d99a0-e531-4b3b-b0f1-1faaa32c14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_fdp_url = fdpclient.create_and_publish(resource_type=\"catalog\", metadata=fdp_catalog_record)\n",
    "print(catalog_fdp_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693bfda-34f0-4f1b-bc5f-b37a86b9bdb9",
   "metadata": {},
   "source": [
    "If everything goes well you should be able to see a new catalog entry in your FDP instance: ![newly created catalog](./imgs/fdp_catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e961c0-8f7e-4d05-82d5-9697aa7f7efa",
   "metadata": {},
   "source": [
    "This time let's prepare a class for an FDP-compartible dataset inheriting from the SeMPyRO DCATDataset.\n",
    "We need to extend the base class with `is_part_of` property similarly as we have done for the catalogue, make the Publisher an Agent and modify the `has_version` field.\n",
    "\n",
    "Another property to add is an identifier. It is not mandatory in the way that FDP does not require this property but it is useful in case you need to update a record in FDP. Each time a record is created in FDP a unique ID is assigned to it. (For the catalogue record example above we have extracted it from the response header) The fact the identifier does not exist before the record is created in an FDP makes it quite hard to track. Hence, having an identifier on the data level is highly recommended to implement incremental updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa68de4-0c1b-4c9c-a885-e77e66ad7011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDPDataset(DCATDataset):\n",
    "    publisher: List[Agent] = Field(description=\"The entity responsible for making the resource available.\",\n",
    "                                   json_schema_extra={\n",
    "                                        \"rdf_term\": DCTERMS.publisher,\n",
    "                                        \"rdf_type\": \"uri\"\n",
    "                                   })\n",
    "    is_part_of: [AnyHttpUrl] = Field(description=\"Link to parent object\",\n",
    "                                     json_schema_extra={\n",
    "                                         \"rdf_term\": DCTERMS.isPartOf,\n",
    "                                         \"rdf_type\": \"uri\"\n",
    "                                     }\n",
    "                                  )\n",
    "    identifier: List[Union[str, LiteralField]] = Field(\n",
    "        description=\"A unique identifier of the resource being described or catalogued.\",\n",
    "        json_schema_extra={\n",
    "            \"rdf_term\": DCTERMS.identifier,\n",
    "            \"rdf_type\": \"rdfs_literal\"\n",
    "        })\n",
    "    has_version: LiteralField = Field(description=\"This resource has a more specific, versioned resource\",\n",
    "                                      json_schema_extra={\n",
    "                                          \"rdf_term\": DCTERMS.hasVersion,\n",
    "                                          \"rdf_type\": \"rdfs_literal\"\n",
    "                                      })\n",
    "\n",
    "    @field_validator(\"has_version\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def convert_to_literal(cls, value: Union[str, LiteralField]) -> List[LiteralField]:\n",
    "        return force_literal_field(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2272d-2c49-4244-bcc1-1b85a2b6335d",
   "metadata": {},
   "source": [
    "Now let's create datasets filling in mandatory fields and some optional which persist in the data and publish them to FDP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60310bf-87d3-478c-b8cf-3b06374b2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in datasets:\n",
    "    dataset = FDPDataset(\n",
    "        title=[LiteralField(value=record[\"name\"])],\n",
    "        description=[LiteralField(value=record[\"description\"])],\n",
    "        identifier=record[\"id\"],\n",
    "        is_part_of=[f\"{catalog_fdp_url}\"],\n",
    "        creator=[record[\"author_id\"]],\n",
    "        release_date=record[\"issued\"],\n",
    "        publisher=[Agent(name=[record[\"publisher_name\"]], identifier=record[\"publisher_id\"])],\n",
    "        theme=record[\"theme\"],\n",
    "        keyword=[LiteralField(value=x) for x in record[\"keywords\"]],\n",
    "        has_version=\"0.1\",\n",
    "    )\n",
    "    dataset_subject = URIRef(f\"http://example.com/dataset_{record['id'][0]}\")\n",
    "    dataset_graph = dataset.to_graph(dataset_subject)\n",
    "    print(dataset_graph.serialize())\n",
    "    dataset_fdp_id = fdpclient.create_and_publish(resource_type=\"dataset\", metadata=dataset_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae279ab-47e8-413e-b0ff-89cd88223168",
   "metadata": {},
   "source": [
    "The catalogue we have created earlier is now updated with 4 datasets ![catalog](./imgs/ds_in_catalog.png)\n",
    "\n",
    "and datasets themselves are available: ![datasets](./imgs/datasets_fdp.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
